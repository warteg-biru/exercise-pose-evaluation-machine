{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6syB5sK0zUry"
   },
   "outputs": [],
   "source": [
    "# TODO:\n",
    "# 1. matching if not all keypoints (added flag to the kps (the third dim))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GeGSGnH8uTZQ"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kevin/.pyenv/versions/3.7.7/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/kevin/.pyenv/versions/3.7.7/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/kevin/.pyenv/versions/3.7.7/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/kevin/.pyenv/versions/3.7.7/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/kevin/.pyenv/versions/3.7.7/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/kevin/.pyenv/versions/3.7.7/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/home/kevin/.pyenv/versions/3.7.7/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/kevin/.pyenv/versions/3.7.7/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/kevin/.pyenv/versions/3.7.7/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/kevin/.pyenv/versions/3.7.7/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/kevin/.pyenv/versions/3.7.7/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/kevin/.pyenv/versions/3.7.7/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'google.colab'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-2450acf19de4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcv2\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpatches\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcv2_imshow\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'google.colab'"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2 as cv\n",
    "# from google.colab.patches import cv2_imshow\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Tiw-xH4ihDy2"
   },
   "outputs": [],
   "source": [
    "# Steps for running:\n",
    "# 1. Download PoseNet model from https://www.tensorflow.org/lite/models/pose_estimation/overview\n",
    "# 2. Choose your template and target image to process\n",
    "# 3. Specify paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KWsKE24V8ayU"
   },
   "outputs": [],
   "source": [
    "model_path = \"posenet_mobilenet_v1_100_257x257_multi_kpt_stripped.tflite\"\n",
    "template_path = \"person.jpg\"\n",
    "target_path = \"person_sit.jpeg\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KKKi017Lujmd"
   },
   "outputs": [],
   "source": [
    "# Load TFLite model and allocate tensors (memory usage method reducing latency)\n",
    "interpreter = tf.lite.Interpreter(model_path=model_path)\n",
    "interpreter.allocate_tensors()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UDmgx42v8AGr"
   },
   "outputs": [],
   "source": [
    "# Get input and output tensors information from the model file\n",
    "input_details = interpreter.get_input_details()\n",
    "output_details = interpreter.get_output_details()\n",
    "\n",
    "height = input_details[0]['shape'][1]\n",
    "width = input_details[0]['shape'][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Z_prEL6J8__I"
   },
   "outputs": [],
   "source": [
    "template_image_src = cv.imread(template_path)\n",
    "# src_tepml_width, src_templ_height, _ = template_image_src.shape \n",
    "template_image = cv.resize(template_image_src, (width, height))\n",
    "cv2_imshow(template_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tyf-ougNRB-r"
   },
   "outputs": [],
   "source": [
    "# can be used later to draw keypoints on the source image (before resizing)\n",
    "# templ_ratio_width = src_tepml_width/width\n",
    "# templ_ratio_height = src_templ_height/height"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eOdfmzuRTk8b"
   },
   "outputs": [],
   "source": [
    "target_image_src = cv.imread(target_path)\n",
    "# src_tar_width, src_tar_height, _ = target_image_src.shape \n",
    "target_image = cv.resize(target_image_src, (width, height))\n",
    "cv2_imshow(target_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QgkhFXI4RnY3"
   },
   "outputs": [],
   "source": [
    "# tar_ratio_width = src_tar_width/width\n",
    "# tar_ratio_height = src_tar_height/height"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MYqpuz9W9gLc"
   },
   "outputs": [],
   "source": [
    "# add a new dimension to match model's input\n",
    "template_input = np.expand_dims(template_image.copy(), axis=0)\n",
    "target_input = np.expand_dims(target_image.copy(), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "x1xGDbfD8GxV"
   },
   "outputs": [],
   "source": [
    "# check the type of the input tensor\n",
    "floating_model = input_details[0]['dtype'] == np.float32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YE1PZY4NBmG4"
   },
   "outputs": [],
   "source": [
    "# Floating point models offer the best accuracy, at the expense of model size \n",
    "# and performance. GPU acceleration requires the use of floating point models.\n",
    "\n",
    "# Brings input values to range from 0 to 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YoJG8LEA9g7R"
   },
   "outputs": [],
   "source": [
    "if floating_model:\n",
    "  template_input = (np.float32(template_input) - 127.5) / 127.5\n",
    "  target_input = (np.float32(target_input) - 127.5) / 127.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 942,
     "status": "ok",
     "timestamp": 1590653318195,
     "user": {
      "displayName": "Ivan Kunyankin",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgkpjkvP0RyJitU5_eXXFoQYaPfVatAMnxmpgNn=s64",
      "userId": "02471114919037225959"
     },
     "user_tz": -180
    },
    "id": "lP5Xm1dn9pOw",
    "outputId": "7ef0105d-5288-449c-f403-b6c013c49089"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "template_heatmaps' shape: (9, 9, 17)\n",
      "template_offsets' shape: (9, 9, 34)\n"
     ]
    }
   ],
   "source": [
    "# Process template image\n",
    "# Sets the value of the input tensor\n",
    "interpreter.set_tensor(input_details[0]['index'], template_input)\n",
    "# Runs the computation\n",
    "interpreter.invoke()\n",
    "# Extract output data from the interpreter\n",
    "template_output_data = interpreter.get_tensor(output_details[0]['index'])\n",
    "template_offset_data = interpreter.get_tensor(output_details[1]['index'])\n",
    "# Getting rid of the extra dimension\n",
    "template_heatmaps = np.squeeze(template_output_data)\n",
    "template_offsets = np.squeeze(template_offset_data)\n",
    "print(\"template_heatmaps' shape:\", template_heatmaps.shape)\n",
    "print(\"template_offsets' shape:\", template_offsets.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "u2CnJ1CGcpi_"
   },
   "outputs": [],
   "source": [
    "# Process target image. Same commands\n",
    "interpreter.set_tensor(input_details[0]['index'], target_input)\n",
    "interpreter.invoke()\n",
    "target_output_data = interpreter.get_tensor(output_details[0]['index'])\n",
    "target_offset_data = interpreter.get_tensor(output_details[1]['index'])\n",
    "target_heatmaps = np.squeeze(target_output_data)\n",
    "target_offsets = np.squeeze(target_offset_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FWG76EIzAuUt"
   },
   "outputs": [],
   "source": [
    "# The output consist of 2 parts:\n",
    "# - heatmaps (9,9,17) - corresponds to the probability of appearance of \n",
    "# each keypoint in the particular part of the image (9,9)(without applying sigmoid \n",
    "# function). Is used to locate the approximate position of the joint\n",
    "# - offset vectors (9,9,34) is called offset vectors. Is used for more exact\n",
    "#  calculation of the keypoint's position. First 17 of the third dimension correspond\n",
    "# to the x coordinates and the second 17 of them correspond to the y coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mPhePFS5aqF_"
   },
   "outputs": [],
   "source": [
    "def parse_output(heatmap_data,offset_data, threshold):\n",
    "\n",
    "  '''\n",
    "  Input:\n",
    "    heatmap_data - hetmaps for an image. Three dimension array\n",
    "    offset_data - offset vectors for an image. Three dimension array\n",
    "    threshold - probability threshold for the keypoints. Scalar value\n",
    "  Output:\n",
    "    array with coordinates of the keypoints and flags for those that have\n",
    "    low probability\n",
    "  '''\n",
    "\n",
    "  joint_num = heatmap_data.shape[-1]\n",
    "  pose_kps = np.zeros((joint_num,3), np.uint32)\n",
    "\n",
    "  for i in range(heatmap_data.shape[-1]):\n",
    "\n",
    "      joint_heatmap = heatmap_data[...,i]\n",
    "      max_val_pos = np.squeeze(np.argwhere(joint_heatmap==np.max(joint_heatmap)))\n",
    "      remap_pos = np.array(max_val_pos/8*257,dtype=np.int32)\n",
    "      pose_kps[i,0] = int(remap_pos[0] + offset_data[max_val_pos[0],max_val_pos[1],i])\n",
    "      pose_kps[i,1] = int(remap_pos[1] + offset_data[max_val_pos[0],max_val_pos[1],i+joint_num])\n",
    "      max_prob = np.max(joint_heatmap)\n",
    "\n",
    "      if max_prob > threshold:\n",
    "        if pose_kps[i,0] < 257 and pose_kps[i,1] < 257:\n",
    "          pose_kps[i,2] = 1\n",
    "\n",
    "  return pose_kps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yhecRA5Wasm7"
   },
   "outputs": [],
   "source": [
    "def draw_kps(show_img,kps, ratio=None):\n",
    "    for i in range(5,kps.shape[0]):\n",
    "      if kps[i,2]:\n",
    "        if isinstance(ratio, tuple):\n",
    "          cv.circle(show_img,(int(round(kps[i,1]*ratio[1])),int(round(kps[i,0]*ratio[0]))),2,(0,255,255),round(int(1*ratio[1])))\n",
    "          continue\n",
    "        cv.circle(show_img,(kps[i,1],kps[i,0]),2,(0,255,255),-1)\n",
    "    return show_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BAu-FoIjAk6W"
   },
   "outputs": [],
   "source": [
    "template_show = np.squeeze((template_input.copy()*127.5+127.5)/255.0)\n",
    "template_show = np.array(template_show*255,np.uint8)\n",
    "template_kps = parse_output(template_heatmaps,template_offsets,0.3)\n",
    "cv2_imshow(draw_kps(template_show.copy(),template_kps))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sGsVUAnKApLS"
   },
   "outputs": [],
   "source": [
    "target_show = np.squeeze((target_input.copy()*127.5+127.5)/255.0)\n",
    "target_show = np.array(target_show*255,np.uint8)\n",
    "target_kps = parse_output(target_heatmaps,target_offsets,0.3)\n",
    "cv2_imshow(draw_kps(target_show.copy(),target_kps))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MdUa-UZetJgp"
   },
   "source": [
    "### Matching by angles and proportions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gn76NvQ6FEsM"
   },
   "source": [
    "#### Set template values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "epsHJ98mGPFO"
   },
   "outputs": [],
   "source": [
    "# Matching keypoints indices in the output of PoseNet\n",
    "# 0. Left shoulder to right shoulder (5-6)\n",
    "# 1. Left shoulder to left elbow (5-7)\n",
    "# 2. Right shoulder to right elbow (6-8)\n",
    "# 3. Left elbow to left wrist (7-9)\n",
    "# 4. Right elbow to right wrist (8-10)\n",
    "# 5. Left hip to right hip (11-12)\n",
    "# 6. Left shoulder to left hip (5-11)\n",
    "# 7. Right shoulder to right hip (6-12)\n",
    "# 8. Left hip to left knee (11-13)\n",
    "# 9. Right hip to right knee (12-14)\n",
    "# 10. Left knee to left ankle (13-15)\n",
    "# 11.  Right knee to right ankle (14-16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EShohUoHi6Ui"
   },
   "outputs": [],
   "source": [
    "parts_to_compare = [(5,6),(5,7),(6,8),(7,9),(8,10),(11,12),(5,11),(6,12),(11,13),(12,14),(13,15),(14,16)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "z-1ZJvOmyfQw"
   },
   "outputs": [],
   "source": [
    "def angle_length(p1, p2):\n",
    "\n",
    "  '''\n",
    "  Input:\n",
    "    p1 - coordinates of point 1. List\n",
    "    p2 - coordinates of point 2. List\n",
    "  Output:\n",
    "    Tuple containing the angle value between the line formed by two input points \n",
    "    and the x-axis as the first element and the length of this line as the second\n",
    "    element\n",
    "  '''\n",
    "\n",
    "  angle = math.atan2(- int(p2[0]) + int(p1[0]), int(p2[1]) - int(p1[1])) * 180.0 / np.pi\n",
    "  length = math.hypot(int(p2[1]) - int(p1[1]), - int(p2[0]) + int(p1[0]))\n",
    "  \n",
    "  return round(angle), round(length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 221
    },
    "colab_type": "code",
    "id": "gw7eTSyijTZc",
    "outputId": "69db2d31-b4de-427a-f281-4d63083eda38"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(180, 33),\n",
       " (-77, 31),\n",
       " (-106, 29),\n",
       " (-90, 27),\n",
       " (-96, 30),\n",
       " (176, 28),\n",
       " (-95, 53),\n",
       " (-90, 51),\n",
       " (-85, 45),\n",
       " (-97, 40),\n",
       " (-109, 34),\n",
       " (-60, 46)]"
      ]
     },
     "execution_count": 40,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "template_values = []\n",
    "for part in parts_to_compare:\n",
    "  template_values.append(angle_length(template_kps[part[0]][:2], template_kps[part[1]][:2]))\n",
    "template_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 221
    },
    "colab_type": "code",
    "id": "M2FdxNHtjgrL",
    "outputId": "ec568d8e-a6b7-46af-bd18-38a535be2789"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(-3, 17),\n",
       " (-126, 36),\n",
       " (-66, 34),\n",
       " (-53, 20),\n",
       " (-119, 18),\n",
       " (0, 20),\n",
       " (-93, 56),\n",
       " (-90, 55),\n",
       " (-89, 53),\n",
       " (-99, 55),\n",
       " (-84, 47),\n",
       " (-98, 48)]"
      ]
     },
     "execution_count": 41,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_values = []\n",
    "for part in parts_to_compare:\n",
    "  target_values.append(angle_length(target_kps[part[0]][:2], target_kps[part[1]][:2]))\n",
    "target_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PUV7Ye7tDKJM"
   },
   "outputs": [],
   "source": [
    "# with open('template.pkl', 'wb') as f:\n",
    "#   pickle.dump(template, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wfRSl-DGDo6u"
   },
   "outputs": [],
   "source": [
    "# with open('template.pkl', 'rb') as f:\n",
    "#   template = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wfZjTUv8iro0"
   },
   "source": [
    "#### Matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "00gXsGUoXNTR"
   },
   "outputs": [],
   "source": [
    "def matching(template_kp, target_kp, angle_deviation=30, size_deviation=1):\n",
    "\n",
    "  '''Input:\n",
    "      1. template_kp - list of tuples (for the template image) containng angles \n",
    "      between particular body parts and x-axis as first elements and its sizes \n",
    "      (distances between corresponding points as second elements)\n",
    "      2. target_kp - same for the target image\n",
    "      3. angle_deviation - acceptable angle difference between corresponding \n",
    "      body parts in the images\n",
    "      4. size_deviation - acceptable proportions difference between the images\n",
    "    Output:\n",
    "      List of body parts which are deviated\n",
    "  '''\n",
    "\n",
    "  devs = []\n",
    "\n",
    "  # set an anchor size for proportions calculations - distance between shoulders\n",
    "  templ_anchor = template_kp[0][1]\n",
    "  targ_anchor = target_kp[0][1]\n",
    "\n",
    "  # for each body part that we calculated angle and size for\n",
    "  for i in range(len(template_kp)):\n",
    "\n",
    "    angles = (template_kp[i][0], target_kp[i][0])\n",
    "    diff_angle = max(angles) - min(angles)\n",
    "\n",
    "    templ_size = (template_kp[i][1],templ_anchor)\n",
    "    templ_size = abs(min(templ_size) / max(templ_size))\n",
    "\n",
    "    tar_size = (target_kp[i][1], targ_anchor)\n",
    "    tar_size = abs(min(tar_size) / max(tar_size))\n",
    "\n",
    "    if diff_angle > angle_deviation:\n",
    "      devs.append(i)\n",
    "      print(\"{0} has different angle\".format(i))\n",
    "\n",
    "    elif max(tar_size,templ_size) - min(tar_size,templ_size) > size_deviation:\n",
    "      devs.append(i)\n",
    "      print(\"{0} has different size\".format(i))\n",
    "\n",
    "  return devs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 136
    },
    "colab_type": "code",
    "id": "DA43MoQeCMe9",
    "outputId": "1bd6587d-de25-438c-a3a2-ff93827ac2bf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 has different angle\n",
      "1 has different angle\n",
      "2 has different angle\n",
      "3 has different angle\n",
      "5 has different angle\n",
      "11 has different angle\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0, 1, 2, 3, 5, 11]"
      ]
     },
     "execution_count": 45,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deviations = matching(template_values, target_values)\n",
    "deviations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FRizaxUNFc4T"
   },
   "source": [
    "#### Draw deviations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3Y5kFK4rFiXR"
   },
   "outputs": [],
   "source": [
    "def draw_deviations(img, keypoints, pairs, deviations):\n",
    "\n",
    "  for i, pair in enumerate(pairs):\n",
    "\n",
    "    if i in deviations:\n",
    "      color = (0,0,255)\n",
    "    else:\n",
    "      color = (0,255,0)\n",
    "      \n",
    "    cv.line(img, (keypoints[pair[0]][1], keypoints[pair[0]][0]), (keypoints[pair[1]][1], keypoints[pair[1]][0]), color=color, lineType=cv.LINE_AA, thickness=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yuoZD2kblA7f"
   },
   "outputs": [],
   "source": [
    "draw_deviations(target_show, target_kps, parts_to_compare, deviations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oTk9BKLdDe1Q"
   },
   "outputs": [],
   "source": [
    "cv2_imshow(target_show)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "9vCudk8Rfbnk",
    "outputId": "6cfc8218-c277-466d-cd50-0b1affbb7e49"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 49,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# cv.imwrite('devs.jpg', target_show)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cVwtNDap-ZeZ"
   },
   "source": [
    "### Matching by finding the target pose in the image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Vd1DFXL8NSly"
   },
   "source": [
    "#### Set a target pattern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zES77R0hLcxf"
   },
   "outputs": [],
   "source": [
    "# Get a zero matrix with the shape of the template image\n",
    "template_pose = np.zeros_like(template_show)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "onh_0-lVPB9p"
   },
   "outputs": [],
   "source": [
    "# connect some of the points \n",
    "def join_point(img, kps):\n",
    "\n",
    "  body_parts = [(5,6),(5,7),(6,8),(7,9),(8,10),(11,12),(5,11),\n",
    "                      (6,12),(11,13),(12,14),(13,15),(14,16)]\n",
    "\n",
    "  for part in body_parts:\n",
    "    cv.line(img, (kps[part[0]][1], kps[part[0]][0]), (kps[part[1]][1], kps[part[1]][0]), \n",
    "            color=(255,255,255), lineType=cv.LINE_AA, thickness=3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3b-o8Y7XZELY"
   },
   "outputs": [],
   "source": [
    "# draw a skeleton of the template pose to the empty image\n",
    "join_point(template_pose, template_kps[:, :2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 274
    },
    "colab_type": "code",
    "id": "BDDvcouZWpzp",
    "outputId": "7c4849c8-ffff-4ee1-88bd-8781b1f5ef95"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=257x257 at 0x7F4D0B6DA400>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "cv2_imshow(template_pose)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_UNgzdSvAo8d"
   },
   "outputs": [],
   "source": [
    "# set the new dimensions of the image to reduce the size\n",
    "buffer = 5 # size of the area around the pose\n",
    "top_left_y = min(template_kps[5:, 0]) - buffer\n",
    "top_left_x = min(template_kps[5:, 1]) - buffer\n",
    "buttom_right_y = max(template_kps[5:, 0]) + buffer\n",
    "buttom_right_x = max(template_kps[5:, 1]) + buffer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0ZaQ8TSJB53y"
   },
   "outputs": [],
   "source": [
    "# crop the template pose with new dimensions\n",
    "template_pose = template_pose[top_left_y:buttom_right_y, top_left_x:buttom_right_x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 158
    },
    "colab_type": "code",
    "id": "3Fibtz40ZVN8",
    "outputId": "48fccb3d-a864-4533-9863-eed905c1b93a"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=61x141 at 0x7F4D0B6DA240>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "cv2_imshow(template_pose)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oqND9GDUAUOa"
   },
   "outputs": [],
   "source": [
    "# save the template pattern\n",
    "# cv.imwrite('template_pose.jpg', template_pose)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2kKUM8XzZZNH"
   },
   "source": [
    "#### Find the pattern in the new image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CVvaKyHjckDj"
   },
   "outputs": [],
   "source": [
    "# Get a zero matrix with the shape of the target image\n",
    "target_pose = np.zeros_like(target_show)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "92zRj8Cecsy6"
   },
   "outputs": [],
   "source": [
    "# draw a skeleton of the target pose to the empty image\n",
    "join_point(target_pose, target_kps[:, :2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PwD0dqcXBIRs"
   },
   "outputs": [],
   "source": [
    "# set the new dimensions of the image to reduce the size\n",
    "buffer = 5 # size of the area around the pose\n",
    "top_left_y = min(target_kps[5:, 0]) - buffer\n",
    "top_left_x = min(target_kps[5:, 1]) - buffer\n",
    "buttom_right_y = max(target_kps[5:, 0]) + buffer\n",
    "buttom_right_x = max(target_kps[5:, 1]) + buffer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "c35Zx7nRBQGw"
   },
   "outputs": [],
   "source": [
    "target_pose = target_pose[top_left_y:buttom_right_y, top_left_x:buttom_right_x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 184
    },
    "colab_type": "code",
    "id": "It0obXgdFhyn",
    "outputId": "432f0a23-c0ef-4888-e81d-915117edb534"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=62x167 at 0x7F4D0B6DA4A8>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "cv2_imshow(target_pose)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9z27IhjIe81l"
   },
   "outputs": [],
   "source": [
    "template_pose = cv.cvtColor(template_pose, cv.COLOR_BGR2GRAY)\n",
    "target_pose = cv.cvtColor(target_pose, cv.COLOR_BGR2GRAY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "y5cAbJ3w-5R4",
    "outputId": "52cce1ff-9294-4f08-b647-f4c7a758bb58"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score: 0.16486926\n",
      "Match\n"
     ]
    }
   ],
   "source": [
    "# the greater the threshold the more exact the pose has to match\n",
    "threshold = 0.1\n",
    "\n",
    "w, h = target_pose.shape[::-1]\n",
    "res = cv.matchTemplate(target_pose,template_pose, cv.TM_CCOEFF_NORMED)\n",
    "score = res.max()\n",
    "\n",
    "print(\"score:\", score)\n",
    "\n",
    "if score >= threshold:\n",
    "  print(\"Match\")\n",
    "else:\n",
    "  print(\"Don't match\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0mrIuPeYthAA"
   },
   "source": [
    "### Draw grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1mxHhuY51LKF"
   },
   "outputs": [],
   "source": [
    "def draw_grid(img, grid_size=9, heatmap=None, part=1):\n",
    "\n",
    "    color = (0,255,255)\n",
    "\n",
    "    small_size = min(img.shape[0], img.shape[1])\n",
    "    cell_size = small_size // grid_size\n",
    "    res = int(small_size % grid_size)\n",
    "\n",
    "    x = res // 2\n",
    "    y = res // 2\n",
    "\n",
    "    while x < img.shape[1]:\n",
    "      cv.line(img, (x, 0), (x, img.shape[0]), color=color, lineType=cv.LINE_AA, thickness=1)\n",
    "      x += cell_size\n",
    "\n",
    "    while y < img.shape[0]:\n",
    "      cv.line(img, (0, y), (img.shape[1], y), color=color, lineType=cv.LINE_AA, thickness=1)\n",
    "      y += cell_size\n",
    "\n",
    "    center_x = res//2\n",
    "    center_y = res//2 + cell_size//2\n",
    "\n",
    "    cv.putText(image,str(round(heatmap[0,0,part],1)), (center_x,center_y), cv.FONT_HERSHEY_SIMPLEX, 0.3, color)\n",
    "\n",
    "    for row_idx, row in enumerate(heatmap[...,part]):\n",
    "\n",
    "      for col_idx, column in enumerate(row):\n",
    "        cv.putText(image,str(round(heatmap[col_idx,row_idx,part],1)), (center_x,center_y), cv.FONT_HERSHEY_SIMPLEX, 0.3, color)\n",
    "        center_y += cell_size\n",
    "        \n",
    "      center_x += cell_size\n",
    "      center_y = res//2 + cell_size//2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4BQbKpR20aTp"
   },
   "outputs": [],
   "source": [
    "# image = cv.imread('image.jpg')\n",
    "# image = cv.resize(image, (257, 257)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fuGHyDus1bRS"
   },
   "outputs": [],
   "source": [
    "# draw_grid(image, 9, template_heatmaps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "j_gS5pZv0kEE"
   },
   "outputs": [],
   "source": [
    "# cv2_imshow(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_15jBuGczrA8"
   },
   "outputs": [],
   "source": [
    "# cv.imwrite('image.jpg', image)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "cVwtNDap-ZeZ",
    "0mrIuPeYthAA"
   ],
   "name": "pose_matching_with_PoseNet.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
